# ğŸ›¡ï¸ Cyber Threat Detection Dashboard

An AI-powered dashboard that helps Security Operations Center (SOC) analysts automatically detect and classify malicious network activity.  
Built with **Machine Learning + Streamlit**, it reduces manual inspection time and improves real-time threat response.

---

## ğŸš€ Features
- ğŸ“‚ Upload raw **CSV network logs** (UNSW-NB15 dataset format)  
- ğŸ”® **Random Forest** model for Safe âœ… vs Unsafe ğŸš¨ detection  
- ğŸ¯ **XGBoost** model for multi-class attack categorization (DoS, Exploits, Reconnaissance, Worms, etc.)  
- ğŸ“Š Interactive **analytics dashboard** (pie charts of Safe vs Unsafe and attack distribution)  
- ğŸ’¾ **Download predictions** as `predictions.csv`  
- âš¡ Instant, no-code insights for SOC analysts  

---

## ğŸ—ï¸ Tech Stack
- **Environment:** Google Colab, VS Code  
- **Libraries:**  
  - `pandas`, `numpy` â†’ data handling  
  - `scikit-learn` â†’ preprocessing, Random Forest, metrics  
  - `xgboost` â†’ attack categorization  
  - `matplotlib` â†’ visualization  
  - `streamlit` â†’ dashboard UI  
  - `joblib` â†’ saving/loading models  

---

## ğŸ“Š Dataset
We used the **[UNSW-NB15 dataset](https://research.unsw.edu.au/projects/unsw-nb15-dataset)**, which contains modern network traffic with both normal logs and multiple types of attacks.  
Key features include:
- `proto` (protocol), `service`, `state`  
- `spkts`, `dpkts`, `sbytes`, `dbytes`  
- `rate`, `dur`, and connection stats  
- `label` â†’ Binary target (0 = Normal, 1 = Attack)  
- `attack_cat` â†’ Multi-class target (DoS, Exploits, Recon, etc.)  

---

## âš™ï¸ Project Workflow
1. **Data Preparation**  
   - Load training & testing datasets  
   - Drop unused metadata columns (`id`, redundant fields)  
   - Encode categorical features (`proto`, `service`, `state`)  
   - Scale numeric features with `StandardScaler`  

2. **Model Training**  
   - **Random Forest (rf_model.pkl):** Binary Safe/Unsafe detection  
   - **XGBoost (xgb_model.pkl):** Multi-class attack classification  
   - Save preprocessing objects (scalers, encoders)  

3. **Model Validation**  
   - Random Forest: ~87% accuracy, high recall for attacks  
   - XGBoost: ~76% accuracy, balanced precision & recall across attack types  
   - Metrics: Accuracy, Precision, Recall, F1-score, Confusion Matrix  

4. **Deployment**  
   - Integrated into **Streamlit dashboard**  
   - Upload â†’ Preprocessing â†’ Prediction â†’ Visualization  
   - Download predictions for offline analysis  


## ğŸ“‚ Folder Structure
cyber-threat-dashboard/
â”‚â”€â”€ data/ # Dataset CSVs (train/test)
â”‚â”€â”€ models/ # Saved ML models & encoders (.pkl)
â”‚â”€â”€ notebook/ # Google Colab training notebooks
â”‚â”€â”€ dashboard.py # Streamlit app
â”‚â”€â”€ sample_logs.csv # Example input CSV
â”‚â”€â”€ README.md # Project documentation
|-- requirements.txt

---

## ğŸ® How to Run
1. Clone the repo:
   ```bash
   git clone https://github.com/zayed789/threat-detection-dashboard.git
   cd threat-detection-dashboard
Install dependencies:
pip install -r requirements.txt
Run the dashboard:

streamlit run dashboard.py
Upload sample_logs.csv (or UNSW-NB15 logs) and view predictions + analytics.

ğŸ“ˆ Results & Impact
Random Forest: 87% accuracy â†’ reliable Safe vs Unsafe detection
XGBoost: 76% accuracy â†’ attack categorization with balanced metrics

Impact:
â±ï¸ Saves hours of manual log inspection
ğŸ§  Reduces analyst fatigue & missed threats
âš¡ Enables faster, more reliable threat response

ğŸ”® Future Work
Real-time log ingestion (streaming data) using LLM'
Explainable AI (feature importance per prediction)
Integration with SIEM tools (Splunk, ELK stack)

# ğŸ›¡ï¸ Cyber Threat Detection Dashboard

An AI-powered dashboard that helps Security Operations Center (SOC) analysts automatically detect and classify malicious network activity.  
Built with **Machine Learning + Streamlit**, it reduces manual inspection time and improves real-time threat response.

---

## ğŸš€ Features
- ğŸ“‚ Upload raw **CSV network logs** (UNSW-NB15 dataset format)  
- ğŸ”® **Random Forest** model for Safe âœ… vs Unsafe ğŸš¨ detection  
- ğŸ¯ **XGBoost** model for multi-class attack categorization (DoS, Exploits, Reconnaissance, Worms, etc.)  
- ğŸ“Š Interactive **analytics dashboard** (pie charts of Safe vs Unsafe and attack distribution)  
- ğŸ’¾ **Download predictions** as `predictions.csv`  
- âš¡ Instant, no-code insights for SOC analysts  

---

## ğŸ—ï¸ Tech Stack
- **Environment:** Google Colab, VS Code  
- **Libraries:**  
  - `pandas`, `numpy` â†’ data handling  
  - `scikit-learn` â†’ preprocessing, Random Forest, metrics  
  - `xgboost` â†’ attack categorization  
  - `matplotlib` â†’ visualization  
  - `streamlit` â†’ dashboard UI  
  - `joblib` â†’ saving/loading models  

---

## ğŸ“Š Dataset
We used the **[UNSW-NB15 dataset](https://research.unsw.edu.au/projects/unsw-nb15-dataset)**, which contains modern network traffic with both normal logs and multiple types of attacks.  
Key features include:
- `proto` (protocol), `service`, `state`  
- `spkts`, `dpkts`, `sbytes`, `dbytes`  
- `rate`, `dur`, and connection stats  
- `label` â†’ Binary target (0 = Normal, 1 = Attack)  
- `attack_cat` â†’ Multi-class target (DoS, Exploits, Recon, etc.)  

---

## âš™ï¸ Project Workflow
1. **Data Preparation**  
   - Load training & testing datasets  
   - Drop unused metadata columns (`id`, redundant fields)  
   - Encode categorical features (`proto`, `service`, `state`)  
   - Scale numeric features with `StandardScaler`  

2. **Model Training**  
   - **Random Forest (rf_model.pkl):** Binary Safe/Unsafe detection  
   - **XGBoost (xgb_model.pkl):** Multi-class attack classification  
   - Save preprocessing objects (scalers, encoders)  

3. **Model Validation**  
   - Random Forest: ~87% accuracy, high recall for attacks  
   - XGBoost: ~76% accuracy, balanced precision & recall across attack types  
   - Metrics: Accuracy, Precision, Recall, F1-score, Confusion Matrix  

4. **Deployment**  
   - Integrated into **Streamlit dashboard**  
   - Upload â†’ Preprocessing â†’ Prediction â†’ Visualization  
   - Download predictions for offline analysis  


## ğŸ“‚ Folder Structure
cyber-threat-dashboard/
â”‚â”€â”€ README.md                  # Project documentation
â”‚â”€â”€ requirements.txt            # Python dependencies
â”‚â”€â”€ dashboard.py                # Streamlit dashboard app
â”‚â”€â”€ sample_logs.csv             # Example CSV for testing

â”œâ”€â”€ data/                       # Datasets
â”‚   â”œâ”€â”€ UNSW_NB15_training-set.csv
â”‚   â”œâ”€â”€ UNSW_NB15_testing-set.csv
â”‚   â””â”€â”€ sample_raw.csv          # Hackathon-friendly sample input

â”œâ”€â”€ models/                     # Trained ML models & encoders
â”‚   â”œâ”€â”€ rf_model.pkl            # Random Forest (binary classification)
â”‚   â”œâ”€â”€ scaler_rf.pkl           # Scaler for RF
â”‚   â”œâ”€â”€ xgb_model.pkl           # XGBoost (multi-class classification)
â”‚   â”œâ”€â”€ scaler_mc.pkl           # Scaler for XGB
â”‚   â”œâ”€â”€ attack_encoder.pkl      # Encoder for attack categories
â”‚   â”œâ”€â”€ proto_encoder.pkl       # Encoder for proto
â”‚   â”œâ”€â”€ service_encoder.pkl     # Encoder for service
â”‚   â””â”€â”€ state_encoder.pkl       # Encoder for state

â”œâ”€â”€ notebook/                   # Jupyter/Colab notebooks
â”‚   â”œâ”€â”€ training_rf.ipynb       # Random Forest training pipeline
â”‚   â”œâ”€â”€ training_xgb.ipynb      # XGBoost training pipeline
â”‚   â””â”€â”€ preprocessing.ipynb     # Data preprocessing & encoding

â”œâ”€â”€ results/                    # Model outputs & evaluation
â”‚   â”œâ”€â”€ rf_metrics.txt          # Accuracy, precision, recall, confusion matrix (RF)
â”‚   â”œâ”€â”€ xgb_metrics.txt         # Same for XGBoost
â”‚   â””â”€â”€ visualizations/         # Any saved plots (confusion matrices, charts, etc.)

â””â”€â”€ docs/                       # Supporting material (optional)
    â”œâ”€â”€ project_pitch.pdf        # Hackathon PPT/Pitch
    â””â”€â”€ architecture.png         # System pipeline diagram
---

## ğŸ® How to Run
1. Clone the repo:
   ```bash
   git clone https://github.com/zayed789/threat-detection-dashboard.git
   cd threat-detection-dashboard
Install dependencies:
pip install -r requirements.txt
Run the dashboard:

streamlit run dashboard.py
Upload sample_logs.csv (or UNSW-NB15 logs) and view predictions + analytics.

ğŸ“ˆ Results & Impact
Random Forest: 87% accuracy â†’ reliable Safe vs Unsafe detection
XGBoost: 76% accuracy â†’ attack categorization with balanced metrics

Impact:
â±ï¸ Saves hours of manual log inspection
ğŸ§  Reduces analyst fatigue & missed threats
âš¡ Enables faster, more reliable threat response

ğŸ”® Future Work
Real-time log ingestion (streaming data) using LLM'
Explainable AI (feature importance per prediction)
Integration with SIEM tools (Splunk, ELK stack)
